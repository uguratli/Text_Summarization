{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "from snowballstemmer import TurkishStemmer\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import news\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "fasttext.util.download_model('tr', if_exists='ignore')\n",
    "ft = fasttext.load_model('cc.tr.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_it(x):\n",
    "    \"\"\"Turkish stemmer.\n",
    "    Returns stemmed words in given string, uses Snowball Turkish stemmer.\"\"\"\n",
    "    return [turkStem.stemWord(w) for w in x.split()]\n",
    "\n",
    "def remove_digit(text):\n",
    "    \"\"\"Digit cleaner.\n",
    "    Removes digits in given string.\"\"\"\n",
    "    digit_pattern = str.maketrans('', '', string.digits)\n",
    "    return text.translate(digit_pattern)\n",
    "\n",
    "def lower_it(text):\n",
    "    \"\"\"Lowers characters in given string.\n",
    "    Lowers all in string.\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "def remove_punctiations(text):\n",
    "    \"\"\"Punction cleaner.\n",
    "    Removes punctions in given string.\"\"\"\n",
    "    pattern = str.maketrans('', '', string.punctuation)\n",
    "    text= text.translate(pattern)\n",
    "    return text.replace(\"\\n\", \" \")\n",
    "\n",
    "def remove_stopwords(text, language='turkish'):\n",
    "    \"\"\"Stopword cleaner.\n",
    "    Removes stopwords in given string, language is set to Turkish by default.\"\"\"\n",
    "    st = stopwords.words(language)\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(st) + r')\\b\\s*')\n",
    "    text = pattern.sub('',text)\n",
    "    return text\n",
    "\n",
    "def replace_turkish(text):\n",
    "    \"\"\"Turkish Character Fixer.\n",
    "    Replaces Turkish character with English ones.\"\"\"\n",
    "    character_map = {'ç': 'c',\n",
    "                     'Ç': 'C',\n",
    "                     'ğ': 'g',\n",
    "                     'Ğ': 'G',\n",
    "                     'ı': 'i',\n",
    "                     'I': 'I',\n",
    "                     'ö': 'o',\n",
    "                     'Ö': 'O',\n",
    "                     'ş': 's',\n",
    "                     'Ş': 'S', \n",
    "                     'ü': 'u',\n",
    "                     'Ü': 'U'}\n",
    "    for initial, final in character_map.items():\n",
    "        text = text.replace(initial, final)\n",
    "    return text\n",
    "\n",
    "def sentence_it(x):\n",
    "    \"\"\"Sentence maker.\n",
    "    Returns one string form of given words array.\"\"\"\n",
    "    sentence = ''\n",
    "    for w in x.split(): sentence += w + \" \"\n",
    "    return sentence.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preproces(text, stemmer=False):\n",
    "    \"\"\"String cleaner.\n",
    "    Removes digits, lowers charactes, removes punctiations and stop words in given string.\"\"\"\n",
    "    text = remove_digit(text)\n",
    "    text = lower_it(text)\n",
    "    text = remove_punctiations(text)\n",
    "    text = remove_stopwords(text)\n",
    "    #text = replace_turkish(text) # Since FastText includes Turkish characters, there is no need to replace them.\n",
    "    # But for different libraries, one may has to change them.\n",
    "    if stemmer:\n",
    "        text = stem_it(text)\n",
    "        text = sentence_it(text)\n",
    "    text = sentence_it(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    \"\"\"Text cleaner.\n",
    "    Returns sentences and cleaned sentences.\"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    clean_sentenes = [preproces(sentence) for sentence in sentences]\n",
    "    return sentences, clean_sentenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector(sentence):\n",
    "    return sum([ft.get_word_vector(word) for word in sentence])/(len(sentence)+0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vectors(text):\n",
    "    \"\"\"Word vector creator.\n",
    "    Uses cleaned text array and returns word vector array\"\"\"\n",
    "    sentence_words = [[w for w in s.split()] for s in text]\n",
    "    word_vectors = [sentence_vector(s_words) for s_words in sentence_words]\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(text_vector):\n",
    "    \"\"\"Similarty Matrix generator.\n",
    "    Creates similarity matrix using sentence vectors via cosine similarity\"\"\"\n",
    "    sim_mat = np.zeros([len(text_vector), len(text_vector)])\n",
    "    for i in range(len(text_vector)):\n",
    "        for j in range(len(text_vector)):\n",
    "            if i != j:\n",
    "                sim_mat[i][j] = cosine_similarity(text_vector[i].reshape(1, -1), text_vector[j].reshape(1, -1))[0, 0]\n",
    "    return sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(sentences, similarity_matrix):\n",
    "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    text_dict = {}\n",
    "    for i in range(len(sentences)):\n",
    "        text_dict.update({str(i):{\"score\": scores[i],\n",
    "                                  \"text\": sentences[i]}})\n",
    "    text_order = sorted(text_dict, key=lambda x: text_dict[x][\"score\"], reverse=True)\n",
    "    extract = \"\"\n",
    "    for i in range(int(len(sentences)/3)):\n",
    "        id = text_order[i]\n",
    "        extract = extract + \" \" + text_dict[id][\"text\"]\n",
    "    return extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_extraction(text):\n",
    "    sentences, cleaned_sentences = text_cleaning(text)\n",
    "    sentence_vectors = word_vectors(cleaned_sentences)\n",
    "    sim_mat = similarity_matrix(sentence_vectors)\n",
    "    return extraction(sentences, sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İsrail İran’ın‘misilleme’saldırısına karşılık vermekten‘son anda’vazgeçti. İran, Suriye’deki büyükelçilik binasını vuran İsrail’e karşı‘misilleme’saldırısı başlatmış, İsrail’e yüzlerce insansız hava aracı  ve füze atılmıştı. İran‘Şimdilik bu kadar’mesajı verince gerilim korkulanın aksinedüşmüştü. İsrail’in İran’ın misillemesinden neredeyse hiç zarar görmemesi gerilimi daha da azalttı.  Yine de İsrail’in olası bir karşı saldırısının gerilimi yeniden tırmandırmasından kaygı duyuluyordu. ABD Başkanı Joe Biden’ın saldırıdan sonra telefonla görüştüğü İsrail Başbakanı Binyamin Netanyahu’dan herhangi bir karşılık verilmemesini istediği öne sürülmüştü. İsrail devlet televizyonu KAN, Netanyahu yönetiminin İran’ın saldırılarına karşılık vermekten‘son anda’bildirdi. Savaş kabinesi ve bakanlar kurulunun önce salt çoğunlukla İran’a derhal karşılık verilmesini onayladığı ancak Biden’la görüşme sonrası bu kararın değiştiği kaydedildi. \n"
     ]
    }
   ],
   "source": [
    "article = news.get_article()\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yine de İsrail’in olası bir karşı saldırısının gerilimi yeniden tırmandırmasından kaygı duyuluyordu. Savaş kabinesi ve bakanlar kurulunun önce salt çoğunlukla İran’a derhal karşılık verilmesini onayladığı ancak Biden’la görüşme sonrası bu kararın değiştiği kaydedildi.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_extraction(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
